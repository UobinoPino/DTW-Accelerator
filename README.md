# DTW Accelerator v1.0 - Concepts-Based Architecture

A high-performance Dynamic Time Warping (DTW) library with a modern C++20 concepts-based architecture supporting multiple parallel backends.

## ğŸš€ Key Features

- **Modern C++20 Concepts**: Type-safe, compile-time polymorphic interface using execution strategies
- **Multiple Backends**: Sequential, Blocked, OpenMP, MPI, and CUDA implementations
- **Unified Interface**: Single algorithm implementation works with all execution strategies
- **Performance Optimized**: Cache-aware blocking, vectorization, wavefront parallelization
- **Memory Efficient**: Contiguous memory layouts with `TimeSeries` and `Matrix` classes
- **Flexible Distance Metrics**: Euclidean, Manhattan, Chebyshev, and Cosine distances
- **Constraint Support**: Sakoe-Chiba band, Itakura parallelogram, and custom windows
- **FastDTW Implementation**: Approximate DTW for large sequences with recursive coarsening

## ğŸ—ï¸ Architecture Overview

### Concepts-Based Design

The library uses C++20 concepts to define a unified interface for execution strategies:

```cpp
template<typename Strategy>
concept ExecutionStrategy = requires(Strategy s, DoubleMatrix& D, 
                                    const DoubleTimeSeries& A, 
                                    const DoubleTimeSeries& B,
                                    int n, int m, int dim) {
    { s.initialize_matrix(D, n, m) } -> std::same_as<void>;
    { s.template execute<MetricType::EUCLIDEAN>(D, A, B, n, m, dim) } -> std::same_as<void>;
    { s.extract_result(D) } -> std::convertible_to<std::pair<double, std::vector<std::pair<int, int>>>>;
    { s.name() } -> std::convertible_to<std::string_view>;
    { s.is_parallel() } -> std::convertible_to<bool>;
};
```

### Core Components

#### Data Structures
- **`TimeSeries<T>`**: Contiguous memory time series with row-major layout
- **`Matrix<T>`**: Contiguous 2D matrix implementation for DTW cost matrix
- **`DoubleTimeSeries`/`DoubleMatrix`**: Type aliases for double precision

#### Execution Strategies
1. **CPU Strategies** (Concepts-based):
    - `SequentialStrategy`: Simple sequential implementation
    - `BlockedStrategy`: Cache-optimized blocked execution
    - `OpenMPStrategy`: Multi-threaded parallel execution with wavefront parallelization
    - `MPIStrategy`: Distributed computing across nodes with block distribution
    - `AutoStrategy`: Automatic strategy selection based on problem size

2. **GPU Strategy** (Specialized):
    - `CUDAStrategy`: Optimized CUDA kernels

#### Algorithm Variants
- **Standard DTW**: Full dynamic programming solution
- **FastDTW**: Recursive coarsening with constrained refinement
- **Constrained DTW**: Window-based constraints for optimization
- **Templated Constraints**: Compile-time constraint specification

### Directory Structure

```
dtw-accelerator/
â”œâ”€â”€ include/dtw_accelerator/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ dtw_concepts.hpp         # C++20 concepts definitions
â”‚   â”‚   â”œâ”€â”€ time_series.hpp          # TimeSeries class
â”‚   â”‚   â”œâ”€â”€ matrix.hpp                # Matrix class
â”‚   â”‚   â”œâ”€â”€ distance_metrics.hpp     # Distance metric implementations
â”‚   â”‚   â”œâ”€â”€ constraints.hpp          # Constraint definitions
â”‚   â”‚   â”œâ”€â”€ path_processing.hpp      # Path utilities
â”‚   â”‚   â””â”€â”€ dtw_utils.hpp           # Common utilities
â”‚   â”œâ”€â”€ execution/
â”‚   â”‚   â”œâ”€â”€ base_strategy.hpp        # CRTP base for strategies
â”‚   â”‚   â”œâ”€â”€ execution_strategies.hpp        
â”‚   â”‚   â”œâ”€â”€ sequential/
â”‚   â”‚   â”‚   â”œâ”€â”€ standard_strategy.hpp
â”‚   â”‚   â”‚   â””â”€â”€ blocked_strategy.hpp
â”‚   â”‚   â”œâ”€â”€ parallel/
â”‚   â”‚   â”‚   â”œâ”€â”€ openmp/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ openmp_strategy.hpp
â”‚   â”‚   â”‚   â”œâ”€â”€ mpi/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mpi_debug_strategy.hpp 
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mpi_strategy.hpp
â”‚   â”‚   â”‚   â””â”€â”€ cuda/
â”‚   â”‚   â”‚         â”œâ”€â”€ cuda_dtw.hpp
â”‚   â”‚   â”‚         â”œâ”€â”€ core/
â”‚   â”‚   â”‚         â”‚   â”œâ”€â”€ cuda_memory.hpp
â”‚   â”‚   â”‚         â”‚   â””â”€â”€ device_functions.cuh
â”‚   â”‚   â”‚         â”œâ”€â”€ execution/
â”‚   â”‚   â”‚         â”‚   â”œâ”€â”€ cuda_launcher.cu
â”‚   â”‚   â”‚         â”‚   â”œâ”€â”€ cuda_launcher.hpp
â”‚   â”‚   â”‚         â”‚   â””â”€â”€ cuda_strategy.hpp
â”‚   â”‚   â”‚         â””â”€â”€ kernels/
â”‚   â”‚   â”‚             â”œâ”€â”€ dtw_core_kernels.cu
â”‚   â”‚   â”‚             â”œâ”€â”€ dtw_core_kernels.cuh
â”‚   â”‚   â”‚             â”œâ”€â”€ matrix_kernels.cu
â”‚   â”‚   â”‚             â”œâ”€â”€ matrix_kernels.cuh
â”‚   â”‚   â”‚             â”œâ”€â”€ path_kernels.cu
â”‚   â”‚   â”‚             â””â”€â”€ path_kernels.cuh
â”‚   â”‚   â””â”€â”€ auto_strategy.hpp
â”‚   â”œâ”€â”€ algorithms/
â”‚   â”‚   â”œâ”€â”€ dtw_generic.hpp          # Generic DTW algorithm
â”‚   â”‚   â”œâ”€â”€ fastdtw_generic.hpp      # FastDTW implementation
â”‚   â””â”€â”€ dtw_accelerator.hpp          # Main header file
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_core.cpp
â”‚   â”œâ”€â”€ test_strategies.cpp
â”‚   â”œâ”€â”€ test_distance_metrics.cpp
â”‚   â”œâ”€â”€ test_constraints.cpp
â”‚   â””â”€â”€ performance/
â”‚       â”œâ”€â”€ benchmark_strategies.cpp
â”‚       â””â”€â”€ benchmark_scaling.cpp
â””â”€â”€ CMakeLists.txt
```

## ğŸ“¦ Installation

### Requirements

- C++20 compatible compiler (GCC 10+, Clang 12+, MSVC 2019+)
- CMake 3.20+
- Optional: OpenMP, MPI, CUDA Toolkit 12.0+

### Building from Source

```bash
git clone https://github.com/UobinoPino/DTW-Accelerator.git
cd dtw-accelerator
mkdir build && cd build

# Configure with desired backends
cmake .. -DCMAKE_BUILD_TYPE=Release \
         -DUSE_OPENMP=ON \
         -DUSE_MPI=ON \
         -DUSE_CUDA=ON \
         -DBUILD_TESTS=ON \
         -DBUILD_BENCHMARKS=ON

# Build
make -j$(nproc)

# Run tests
TODO

# Install
sudo make install
```

## ğŸ¯ Usage Examples

TODO

### Custom Strategy Implementation

```cpp
class MyCustomStrategy : public BaseStrategy<MyCustomStrategy> {
public:
    template<distance::MetricType M>
    void execute(DoubleMatrix& D,
                 const DoubleTimeSeries& A,
                 const DoubleTimeSeries& B,
                 int n, int m, int dim) const {
        // Your custom implementation
        //.....
        
        .....//
        for (int i = 1; i <= n; ++i) {
            for (int j = 1; j <= m; ++j) {
                D(i, j) = utils::compute_cell_cost<M>(
                    A[i-1], B[j-1], dim,
                    D(i-1, j-1), D(i, j-1), D(i-1, j)
                );
            }
        }
    }
    
    std::string_view name() const { return "MyCustom"; }
    bool is_parallel() const { return false; }
};

// Use custom strategy
MyCustomStrategy custom;
auto result = dtw<MetricType::EUCLIDEAN>(series_a, series_b, custom);
```

## ğŸ”§ Advanced Features

### MPI Usage

```bash
# Compile with MPI support
mpicxx -std=c++20 -DUSE_MPI your_program.cpp -o your_program

# Run with multiple processes
mpirun -np 4 ./your_program
```

## ğŸ“Š Performance Characteristics

### Complexity
- **Time Complexity**: O(nÃ—m) for standard DTW
- **Space Complexity**: O(nÃ—m) for cost matrix
- **FastDTW**: O(n) approximate with controllable accuracy

### Memory Layout Benefits
- **TimeSeries**: Contiguous memory, better cache locality
- **Matrix**: Single allocation, reduced fragmentation
- **Direct pointer access**: Efficient for CUDA/MPI transfers

### Parallelization Strategies
- **OpenMP**: Wavefront parallelization with blocked processing
- **MPI**: Distributed block processing with boundary exchange
- **CUDA**: GPU acceleration for large sequences (>1000 points)

## ğŸ›ï¸ Design Principles

### Concepts:
1. **Type Safety**: Compile-time verification of strategy interfaces
2. **Zero Overhead**: No virtual function calls or runtime polymorphism
3. **Extensibility**: Easy to add new strategies without modifying core
4. **Clear Contracts**: Concepts explicitly define requirements
5. **Better Error Messages**: Clearer compiler diagnostics

### Memory Efficiency
- Contiguous memory allocation reduces cache misses
- Row-major layout optimizes sequential access patterns
- Blocked processing improves temporal locality
- Minimal memory overhead compared to nested vectors

## ğŸ—ºï¸ Roadmap

- [ ] Distributed CUDA with NCCL
- [ ] Python bindings with pybind11


## ğŸ“„ License

See LICENSE file for details

## ğŸ“š Citation

If you use DTW Accelerator in your research, please cite:

```bibtex
@software{dtw_accelerator,
  title = {DTW Accelerator: A Modern C++20 Concepts-Based Dynamic Time Warping Library},
  author = {UobinoPino},
  year = {2024},
  url = {https://github.com/UobinoPino/DTW-Accelerator}
}
```

## ğŸ”— References

1. [Dynamic Time Warping](https://en.wikipedia.org/wiki/Dynamic_time_warping)
2. [FastDTW Algorithm](https://cs.fit.edu/~pkc/papers/tdm04.pdf)
3. [C++20 Concepts](https://en.cppreference.com/w/cpp/language/constraints)
4. [Wavefront Parallel Pattern](https://en.wikipedia.org/wiki/Wavefront_pattern)
